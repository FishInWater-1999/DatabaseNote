# HashMap 扩容机制是什么样的？



15s 一个点 （大概六行 71 个字）



2 

1、hashmap

2、大数据

大数据杀熟



韭菜：hashmap上的数据过多时

查寻的效率就会变低

这时就需要扩容

以便在存储更多数据的同时

保证较高运行的效率

旁白：咦~ 太胖了

张三：那怎样才能判断出

 hashmap 的扩容时机呢？

韭菜：衡量这一标准的是负载因子

当数据大于容量与负载因子的乘积时

hashmap 就会进行扩容啦

旁白：你这是长高，不是扩容

由于负载因子大小为 0.75f 

因此一个容量为 16 的 HashMap

当插入第 13 个元素时就会扩容啦

张三：那扩容的过程都干了什么呢？

韭菜：Hashmap 的扩容会先创建一个

原数组两倍大的新数组

接着去遍历原数组

将所有 entry 都挪到新数组中去

旁白：我被掏空了

张三：那扩容后为什么要重新 Hash 呢？

韭菜：这和 hash 值的计算有关

我们知道 hash 值是通过

HashCode 余上长度减一「HashCode & (Length - 1)」

这个公式计算的

所以当长度发生变化时

hash 值也会随之而变化

旁白：这节点变味(位)了

张三：那迁移时为什么使用尾插法呢？

韭菜：其实在 jdk 1.7 中

扩容是采用的是头插法

但头插法会改变节点的排列

因此在多线程场景下

原先按顺序排列的的链表

就有可能出现首尾相连的问题

旁白：我好想闻到了脚气

韭菜：所以 jdk 1.8 后就改用尾插法啦

因为尾插法不会影响原有的顺序

也就解决了节点相连成环的问题

其实 HashMap 的扩容过程

对效率的影响是很大的

因此建议在初始化时

就设定数组的容量

以免反复扩容影响运行效率

我是黎明韭菜，一个怎么么吃都不胖的程序员